import os
import json
import torch
from transformers import BertTokenizerFast, BertForSequenceClassification

# æ¨¡å‹èˆ‡è·¯å¾‘
MODEL_DIR = "./bert_output/basketball-bert"
INPUT_DIR = "./articles/unlabeled_articles"
OUTPUT_DIR = "./articles/predicted_articles"

# é¡åˆ¥æ¨™ç±¤å°æ‡‰
label_map = {
    0: "è³½äº‹æˆ°å ±",
    1: "çƒéšŠåˆ†æ",
    2: "çƒå“¡ç„¦é»",
    3: "äº¤æ˜“èˆ‡ç°½ç´„",
    4: "æ•™ç·´èˆ‡ç®¡ç†å±¤",
    5: "é¸ç§€è§€å¯Ÿ",
    6: "æ­·å²èˆ‡å°ˆé¡Œ"
}

# è¼‰å…¥æ¨¡å‹èˆ‡ tokenizer
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
tokenizer = BertTokenizerFast.from_pretrained(MODEL_DIR)
model = BertForSequenceClassification.from_pretrained(MODEL_DIR)
model.to(device)
model.eval()

def predict(text):
    encoding = tokenizer(text, return_tensors='pt', padding=True, truncation=True, max_length=512)
    encoding = {k: v.to(device) for k, v in encoding.items()}
    with torch.no_grad():
        output = model(**encoding)
        pred = torch.argmax(output.logits, dim=1).item()
    return label_map[pred]

# é æ¸¬ä¸¦è¼¸å‡ºè‡³æ–°è³‡æ–™å¤¾
os.makedirs(OUTPUT_DIR, exist_ok=True)
count = 0

for filename in os.listdir(INPUT_DIR):
    if filename.endswith(".json"):
        input_path = os.path.join(INPUT_DIR, filename)
        output_path = os.path.join(OUTPUT_DIR, filename)
    try:
        with open(input_path, 'r', encoding='utf-8') as f:
            data = json.load(f)

        content = " ".join(data.get("article-content", []))
        if not content.strip():
            continue

        prediction = predict(content)
        data["predicted_category"] = prediction

        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)

        print(f"âœ… {filename} â†’ {prediction}")
        count += 1

    except Exception as e:
        print(f"âŒ éŒ¯èª¤è™•ç† {filename}ï¼š{e}")
print(f"\nğŸ‰ é æ¸¬å®Œæˆï¼Œå…±è¼¸å‡º {count} ç¯‡è‡³ï¼š{OUTPUT_DIR}")