import os
import json
from datetime import datetime, timedelta
from sentence_transformers import SentenceTransformer, util
import torch

# 1. è¼‰å…¥æ¨¡å‹
model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')

# 2. è®€å–æ‰€æœ‰æ–‡ç« ï¼ˆåŸå§‹è³‡æ–™ï¼‰
folder_path = "articles/predicted_articles"
articles = {}
corpus_embeddings = []
article_ids = []
article_dates = {}

for filename in os.listdir(folder_path):
    if filename.endswith(".json"):
        file_path = os.path.join(folder_path, filename)
        with open(file_path, "r", encoding="utf-8") as f:
            data = json.load(f)
        
        article_id = data["id"]
        title = data["title"]
        tags = " ".join(data.get("tags", []))
        body = "".join(data["article-content"])
        full_text = title + "ã€‚" + tags + "ã€‚" + body

        date_str = data["date"]
        date_obj = datetime.strptime(date_str, "%Y/%m/%d")
        article_dates[article_id] = date_obj

        embedding = model.encode(full_text, convert_to_tensor=True, normalize_embeddings=True)

        articles[article_id] = full_text
        corpus_embeddings.append(embedding)
        article_ids.append(article_id)

# 3. è®€å–æŸ¥è©¢æ–‡ç« 
target_id = "118870"
target_file_path = os.path.join(folder_path, f"{target_id}.json")

with open(target_file_path, "r", encoding="utf-8") as f:
    data = json.load(f)

target_date = datetime.strptime(data["date"], "%Y/%m/%d")
target_text = data["title"] + "ã€‚" + " ".join(data.get("tags", [])) + "ã€‚" + "".join(data["article-content"])

# 4. å»ºç«‹æŸ¥è©¢æ–‡ç«  embedding
target_embedding = model.encode(target_text, convert_to_tensor=True, normalize_embeddings=True)

# 5. éæ¿¾æ—¥æœŸ Â±10 å¤©å…§çš„æ–‡ç« 
start_date = target_date - timedelta(days=10)
end_date = target_date + timedelta(days=10)

filtered_embeddings = []
filtered_ids = []

for i, aid in enumerate(article_ids):
    if aid == target_id:
        continue
    article_date = article_dates[aid]
    if start_date <= article_date <= end_date:
        filtered_embeddings.append(corpus_embeddings[i])
        filtered_ids.append(aid)

# 6. è¨ˆç®—ç›¸ä¼¼åº¦ï¼ˆcosine similarityï¼‰
if not filtered_embeddings:
    print("âš ï¸ æ²’æœ‰åœ¨ Â±10 å¤©å…§çš„å…¶ä»–æ–‡ç« å¯ä¾›æ¯”è¼ƒã€‚")
else:
    filtered_tensor = torch.stack(filtered_embeddings)
    cos_scores = util.cos_sim(target_embedding, filtered_tensor)[0]

    # 7. æ‰¾å‡ºå‰3ç¯‡æœ€ç›¸ä¼¼
    top_results = sorted(list(enumerate(cos_scores)), key=lambda x: x[1], reverse=True)

    print(f"ğŸ” å’Œæ–‡ç«  {target_id} æœ€ç›¸ä¼¼çš„3ç¯‡æ–‡ç« ï¼ˆé™å®š Â±10 å¤©å…§ï¼‰ï¼š\n")
    for idx, score in top_results[:3]:
        similar_id = filtered_ids[idx]
        print(f"ğŸ“„ æ–‡ç«  IDï¼š{similar_id}, ç›¸ä¼¼åº¦ï¼š{score:.4f}")
        print(f"â¡ï¸ æ–‡ç« ç‰‡æ®µï¼š{articles[similar_id][:50]}...\n")
